{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7orpZtWBS4J"
      },
      "source": [
        "# Partner Performance Insights - Business Case\n",
        "\n",
        "## Introduction\n",
        "\n",
        "This project aims to analyze a dataset representing visits and payments to partners, including details on activities, segments, and payment types. To conduct the analysis, I will use **Python** for data preparation, validation, and cleaning due to its flexibility and efficiency. After this stage, the data will be exported in **CSV** format and imported into **SQL Server Management Studio (SSMS)**, where it will be structured and processed to identify key correlations and extract strategic insights.\n",
        "\n",
        "## Understanding the Case\n",
        "\n",
        "Before starting any analysis, it is essential to clearly define the problem to be solved. The purpose of this phase is to establish the analysis objectives and define key assumptions that will guide the project.\n",
        "\n",
        "### Objective\n",
        "\n",
        "The provided data represents visits and payments made to partners. Within this context, I am responsible for developing data-driven insights for the platform that manages these partners. The key objectives include:\n",
        "\n",
        "\n",
        "\n",
        "*   Conducting an exploratory analysis of the provided data.\n",
        "*   Generating strategic insights to enhance partner engagement and operational efficiency.\n",
        "*   Presenting the findings through comprehensive documentation, structured queries, insightful dashboards, and an executive presentation.\n",
        "\n",
        "There are no restrictions on the tools used; however, it is mandatory that the documentation, queries, dashboard, and presentation be delivered in English.\n",
        "\n",
        "### Assumptions\n",
        "\n",
        "During the initial data assessment, the following assumptions were made to ensure consistent calculations and interpretations:\n",
        "\n",
        "* CAP Adjustment → Upon reviewing the provided datasets, I identified that the CAP value is approximately 10 times the session cost. Based on the case description, which defines the CAP (Maximum Payment Limit) as the maximum amount that can be paid per visit, and considering the provided example where the session cost is close to the CAP value, we adjusted this metric by dividing the reported CAP by 10.\n",
        "\n",
        "* Classification of Payment Type → The \"Retroactive\" payment type was classified as completed sessions, which were paid with a certain delay.\n",
        "\n",
        "* CAP Hit Calculation → To calculate the CAP hit metric, we considered transactions where the CAP is equal to the actual session cost as having reached the payment limit.\n",
        "\n",
        "## Understanding the Data\n",
        "\n",
        "At this stage, we analyze the metadata of the provided datasets and apply data transformations to inspect, clean, and extract key information for further analysis. The initial processing ensures that the data is properly structured before deeper exploration.\n",
        "\n",
        "### Initial Setup\n",
        "\n",
        "At this stage, we load all the libraries that will be used throughout the project. This approach optimizes the workflow by reducing redundant imports and ensuring better code organization.\n",
        "\n",
        "At this stage, we will examine each table individually to understand the data they contain and their respective information. This process is essential to ensure a clear understanding of the data structure before proceeding with the analysis.\n",
        "\n",
        "### Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FgryHA6j_4Eb"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pandas'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m files\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from google.colab import files\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "IINpBDNqALMk",
        "outputId": "c2e8543b-8458-4a51-b8e9-1b4961b7a515"
      },
      "outputs": [],
      "source": [
        "uploaded = files.upload()  #This will open a window to select the CSV file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1EecKkSAXZl"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"Case Partner Ops Data - Table1_partners_payout.csv\") #Reading Table 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubbBqoHdTBXu"
      },
      "source": [
        "The table **Case Partner Ops Data - Table1_partners_payout.csv** presents inconsistencies in the date format within the **flt_pyt_session_considered_at_localtime column**, containing values in different formats within the same column.\n",
        "\n",
        "Additionally, the numeric columns **flt_pyt_transaction_cost** and **flt_pyt_product_cap** are stored in different data types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwhnQVwpC6ae",
        "outputId": "55f01ef4-314d-4709-e7b9-a9098ebf8fef"
      },
      "outputs": [],
      "source": [
        "print(df.head(5)) #Displays the first 5 rows of the dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDDWcexeUwC8"
      },
      "source": [
        "As shown below, **flt_pyt_transaction_cost** is represented as a floating-point number, while flt_pyt_product_cap is stored as an integer.\n",
        "\n",
        "To ensure data consistency, all numeric columns will be standardized to the floating-point format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOSkRl1nDRCO",
        "outputId": "06498d0c-c754-4931-e38e-15360f044a78"
      },
      "outputs": [],
      "source": [
        "print(df.info())  #Displays data types and null values.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2nGtz02WmEM"
      },
      "source": [
        "Since the column **flt_pyt_session_considered_at_localtime** contains dates in both correct and incorrect formats, we need to identify only those that require correction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVoxbDnQEGK-"
      },
      "outputs": [],
      "source": [
        "#Function to correct only the dates in the incorrect format\n",
        "def corrigir_data(data):\n",
        "    try:\n",
        "        #Attempts to directly convert to the correct format.\n",
        "        return datetime.strptime(data, \"%Y-%m-%d %H:%M:%S\").strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    except ValueError:\n",
        "        #If an error occurs, it indicates that the date is in the wrong format and requires correction\n",
        "        return datetime.strptime(data, \"%m/%d/%Y %H:%M:%S\").strftime(\"%Y-%m-%d %H:%M:%S\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mxd4M4SF89_"
      },
      "outputs": [],
      "source": [
        "#Apply the correction only to the incorrect dates.\n",
        "df['flt_pyt_session_considered_at_localtime'] = df['flt_pyt_session_considered_at_localtime'].astype(str).apply(corrigir_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7Ij8pBvGeRE",
        "outputId": "fe8cf198-2d97-4a1f-e3cd-2cc335f70a54"
      },
      "outputs": [],
      "source": [
        "print(df[['flt_pyt_session_considered_at_localtime']].head(5)) #Verified if the correction worked.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9r6jwpn-eR2l"
      },
      "source": [
        "After correcting the date format, the **flt_pyt_product_cap** column was normalized to a floating-point format by applying the correction of dividing by 10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9sTgK1hNIw3"
      },
      "outputs": [],
      "source": [
        "#Convert the columns to float.\n",
        "df['flt_pyt_transaction_cost'] = df['flt_pyt_transaction_cost'].astype(float)\n",
        "df['flt_pyt_product_cap'] = df['flt_pyt_product_cap'].astype(float) / 10  #Dividing by 10\n",
        "\n",
        "#Replace the period with a comma in the specified columns.\n",
        "df['flt_pyt_transaction_cost'] = df['flt_pyt_transaction_cost'].apply(lambda x: str(x).replace('.', ','))\n",
        "df['flt_pyt_product_cap'] = df['flt_pyt_product_cap'].apply(lambda x: str(x).replace('.', ','))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpwIW8Rh0RTV",
        "outputId": "6e6050b5-e006-48c3-e146-cc19f5b528b7"
      },
      "outputs": [],
      "source": [
        "print(df[['flt_pyt_transaction_cost', 'flt_pyt_product_cap']].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0b8pN2GfdKi"
      },
      "source": [
        "After the correction, the file was saved as *'Case Partner Ops Data - Table1_partners_payout_adjusted.csv'* and downloaded in **CSV** format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "NahZo3eeWAiH",
        "outputId": "bfd59c7d-ed7f-441d-c7a9-1ecf9ec67028"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"Case Partner Ops Data - Table1_partners_payout_adjusted.csv\", index=False)\n",
        "files.download(\"Case Partner Ops Data - Table1_partners_payout_adjusted.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoOZhroAf-64"
      },
      "source": [
        "With the first table completed, we will now review the data in the table *'Case Partner Ops Data - Table2_dimension_store.partners.csv'* to determine if any corrections are needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "id": "kHZGY9l7kh72",
        "outputId": "60bb35fd-8d77-47e7-ccc1-0baa013916d6"
      },
      "outputs": [],
      "source": [
        "uploaded = files.upload()  #This will open a window to select the CSV file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHRDCwKGkmjX"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"Case Partner Ops Data - Table2_dimension_store.partners.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4_LI893koft",
        "outputId": "c80717b6-cccd-4822-fdae-01aa209009c5"
      },
      "outputs": [],
      "source": [
        "print(df.head(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHBf_XRRgrcE"
      },
      "source": [
        "As this is a dimension table, no need for corrections was identified in the *'Case Partner Ops Data - Table2_dimension_store.partners.csv'* table. Therefore, we will proceed with the original table as received in the case presentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEkhqiRokq_s",
        "outputId": "b7fe471f-e6b9-4cd0-a365-2b24eed563fa"
      },
      "outputs": [],
      "source": [
        "print(df.info())  #Displays data types and null values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-4EwYZthEqL"
      },
      "source": [
        "With the second table requiring no corrections, we will now move on to the table *'Case Partner Ops Data - Table3_dimension_store.partner_products.csv'* to assess the need for any data corrections and cleaning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        },
        "id": "-ZuYg_BckvTA",
        "outputId": "ae114c70-dac9-4980-cd61-d5318c8e9cab"
      },
      "outputs": [],
      "source": [
        "uploaded = files.upload()  #This will open a window to select the CSV file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ra23Unpkz04"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"Case Partner Ops Data - Table3_dimension_store.partner_products.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZcqdH4YhJtb"
      },
      "source": [
        "As verified below, the table *'Case Partner Ops Data - Table3_dimension_store.partner_products.csv'* has the columns **product_cost_per_usage** and **product_cap_value** as integers, and the column **last_price_update** in the correct date format but without hours, minutes, and seconds. To align with the format of the table *'Case Partner Ops Data - Table1_partners_payout.csv'*, we will convert the columns **product_cost_per_usage** and **product_cap_value** to floating-point numbers and the column **last_price_update** to a datetime format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ot9gBXcqk402",
        "outputId": "5be047d0-5209-4a40-cc76-6da470f056df"
      },
      "outputs": [],
      "source": [
        "print(df.head(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xreB4kMymGTw",
        "outputId": "faae06db-9fee-48ab-d638-e1649315fd10"
      },
      "outputs": [],
      "source": [
        "#First, ensure that the column is in datetime format.\n",
        "df['last_price_update'] = pd.to_datetime(df['last_price_update'], format='%Y-%m-%d')\n",
        "\n",
        "#Now, add the desired time. If not specified, we will add 00:00:00.\n",
        "df['last_price_update'] = df['last_price_update'].dt.strftime('%Y-%m-%d 0:00:00')\n",
        "\n",
        "# Verificar se a transformação foi realizada corretamente\n",
        "print(df[['last_price_update']].head(5))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUJfmwrsmo70"
      },
      "outputs": [],
      "source": [
        "#Convert the columns to float.\n",
        "df['product_cost_per_usage'] = df['product_cost_per_usage'].astype(float)\n",
        "df['product_cap_value'] = df['product_cap_value'].astype(float) / 10  #Dividing by 10\n",
        "\n",
        "#Replace the period with a comma in the specified columns.\n",
        "df['product_cost_per_usage'] = df['product_cost_per_usage'].apply(lambda x: str(x).replace('.', ','))\n",
        "df['product_cap_value'] = df['product_cap_value'].apply(lambda x: str(x).replace('.', ','))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1PAuU9Sm5O-",
        "outputId": "f30926d0-9951-4f34-860a-d06d25cd82f7"
      },
      "outputs": [],
      "source": [
        "print(df.info())  #Displays data types and null values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2f15sBj4_EpM",
        "outputId": "50aa7dc1-56c3-44f1-db9c-17d40ccebb30"
      },
      "outputs": [],
      "source": [
        "print(df[['product_cost_per_usage', 'product_cap_value']].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPJoLBgvjWG3"
      },
      "source": [
        "After the correction, the file was saved as *'Case Partner Ops Data - Table3_dimension_store.partner_products_adjusted.csv'* and downloaded in **CSV** format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "aUxblwgxnCh5",
        "outputId": "39dad7ae-1887-40d1-865f-3824c4260025"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"Case Partner Ops Data - Table3_dimension_store.partner_products_adjusted.csv\", index=False)\n",
        "files.download(\"Case Partner Ops Data - Table3_dimension_store.partner_products_adjusted.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkRWupb6jdTR"
      },
      "source": [
        "With all corrections completed and the datasets downloaded, we can proceed with structuring the databases in **SSMS** and crafting the queries that will provide us with the key insights.\n",
        "The documentation, which includes a detailed step-by-step guide for structuring the databases and the formulated queries, can be accessed through the following [link](https://github.com/eliabearaujo/partner-payments-bi/blob/25694f410afb4782257109f226ddb81297cb6b23/SQL%20Documentation.md)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
